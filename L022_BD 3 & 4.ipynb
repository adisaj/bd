{"cells":[{"cell_type":"markdown","source":["**K-shingles and Min Hashing**\n","\n","Aditya Pulikal / MSc DSAI / L022"],"metadata":{"id":"PCxx5F2hYGpe"},"id":"PCxx5F2hYGpe"},{"cell_type":"code","execution_count":null,"id":"c4eeccab-e130-4055-9faa-5b270abf2dfd","metadata":{"id":"c4eeccab-e130-4055-9faa-5b270abf2dfd","outputId":"7185e55f-e0b9-4400-b97d-78982775ebc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["1650\n","                                              Row  Document 1  Document 2  \\\n","ofHiroshimaandNagasakiat                        0         0.0         0.0   \n","itsgreatpowerswanedtriggering                   1         0.0         1.0   \n","crippledtheJapaneseNavyand                      2         0.0         1.0   \n","causingwidespreaddestructionandthe              3         0.0         0.0   \n","economicindustrialandscientificcapabilities     4         0.0         1.0   \n","...                                           ...         ...         ...   \n","the21stcenturyTheUnited                      1645         0.0         1.0   \n","tensionsbetweenthegreatpowers                1646         1.0         0.0   \n","andsocialstructureofthe                      1647         0.0         1.0   \n","on3SeptemberUndertheir                       1648         0.0         1.0   \n","intheSovietUnionKey                          1649         0.0         1.0   \n","\n","                                             Document 3  \n","ofHiroshimaandNagasakiat                            1.0  \n","itsgreatpowerswanedtriggering                       0.0  \n","crippledtheJapaneseNavyand                          0.0  \n","causingwidespreaddestructionandthe                  1.0  \n","economicindustrialandscientificcapabilities         0.0  \n","...                                                 ...  \n","the21stcenturyTheUnited                             0.0  \n","tensionsbetweenthegreatpowers                       0.0  \n","andsocialstructureofthe                             0.0  \n","on3SeptemberUndertheir                              0.0  \n","intheSovietUnionKey                                 0.0  \n","\n","[1650 rows x 4 columns]\n"]}],"source":["import string\n","import numpy as np\n","import pandas as pd\n","def read_file(file_path):\n","    with open(file_path,'r') as file:\n","        text=file.read()\n","    return text\n","#f=open(\"Desktop/worldwar1.txt\",\"r\")\n","#text=f.read()\n","\n","def remove_punctuation(text):\n","    translator=str.maketrans('','',string.punctuation)\n","    cleaned_text=text.translate(translator)\n","    words=cleaned_text.split()\n","    return words\n","#print(cleaned_text)\n","\n","\n","#for word in words:\n","    #print(word)\n","def generate_k_shingles(words,k):\n","    k_shingles=[''.join(words[i:i+k]) for i in range(len(words)-k+1)]\n","    return k_shingles\n","\n","k=5\n","file_path1='Desktop/worldwar1.txt'\n","text1=read_file(file_path1)\n","words1=remove_punctuation(text1)\n","shingles1=generate_k_shingles(words1,k)\n","#for shingle in shingles1:\n"," #   print(shingle)\n","\n","file_path2='Desktop/worldwar2.txt'\n","text2=read_file(file_path2)\n","words2=remove_punctuation(text2)\n","shingles2=generate_k_shingles(words2,k)\n","#for shingle in shingles2:\n","    #print(shingle)\n","\n","file_path3='Desktop/worldwar3.txt'\n","text3=read_file(file_path3)\n","words3=remove_punctuation(text3)\n","shingles3=generate_k_shingles(words3,k)\n","#for shingle in shingles3:\n","    #print(shingle)\n","\n","all_shingles=shingles1+shingles2+shingles3\n","#print(all_shingles)\n","\n","\n","\n","\n","\n","\n","#unique_shingles=list(set(all_shingles))\n","#print(unique_shingles)\n","#incidence_matrix=np.zeros((len(unique_shingles),len(a1)),dtype=int)\n","\n","\n","\n","#for i, unique_shingle in enumerate(unique_shingles):\n"," #   for j, shingle in enumerate(a1):\n","  #      if unique_shingle==a1:\n","   #         incidence_matrix[i][j]=1\n","\n","#print(incidence_matrix)\n","\n","\n","# Step 1: Combine all shingles and find unique shingles\n","unique_shingles = list(set(all_shingles))\n","print(len(unique_shingles))\n","# Step 2: Initialize an empty incidence matrix\n","incidence_matrix = np.zeros((len(unique_shingles), 3))  # 3 documents in this case\n","\n","# Step 3: Populate the incidence matrix\n","for i, shingle in enumerate(unique_shingles):\n","    if shingle in shingles1:\n","        incidence_matrix[i, 0] = 1  # Document 1\n","    if shingle in shingles2:\n","        incidence_matrix[i, 1] = 1  # Document 2\n","    if shingle in shingles3:\n","        incidence_matrix[i, 2] = 1  # Document 3\n","\n","# Step 4: Create a DataFrame for better visualization (optional)\n","incidence_df = pd.DataFrame(incidence_matrix, index=unique_shingles, columns=[\"Document 1\", \"Document 2\", \"Document 3\"])\n","incidence_df.insert(0,\"Row\",range(0,len(unique_shingles)))\n","# Print the incidence matrix\n","print(incidence_df)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"7e50527c-6e75-456a-ab00-d2723eb97a18","metadata":{"id":"7e50527c-6e75-456a-ab00-d2723eb97a18","outputId":"c6d9df1a-e0c6-4a01-a3dc-445c942202bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                           Row  Document 1  Document 2  \\\n","useofnuclearweaponsor                      999         0.0         0.0   \n","ofHiroshimaandNagasakiat                     0         0.0         0.0   \n","SicilyandtheItalianmainland               1000         0.0         1.0   \n","itsgreatpowerswanedtriggering                1         0.0         1.0   \n","liberationofGermanoccupiedterritoriesthe  1001         0.0         1.0   \n","...                                        ...         ...         ...   \n","Keysetbacksin1943â€”includingGerman        994         0.0         1.0   \n","Hiroshimaon6Augustand                      995         0.0         1.0   \n","warfareandtheuseof                         996         1.0         0.0   \n","theEnglishChanneltoSwitzerland             997         1.0         0.0   \n","andothercountriesInJune                    998         0.0         1.0   \n","\n","                                          Document 3   h1   h2  \n","useofnuclearweaponsor                            1.0    0    3  \n","ofHiroshimaandNagasakiat                         1.0    1    5  \n","SicilyandtheItalianmainland                      0.0    1    5  \n","itsgreatpowerswanedtriggering                    0.0    2    7  \n","liberationofGermanoccupiedterritoriesthe         0.0    2    7  \n","...                                              ...  ...  ...  \n","Keysetbacksin1943â€”includingGerman              0.0  995  993  \n","Hiroshimaon6Augustand                            0.0  996  995  \n","warfareandtheuseof                               0.0  997  997  \n","theEnglishChanneltoSwitzerland                   0.0  998  999  \n","andothercountriesInJune                          0.0  999    1  \n","\n","[1650 rows x 6 columns]\n"]}],"source":["#apply Hash Function\n","incidence_df['h1'] = (incidence_df['Row']+1) % 1000\n","incidence_df['h2'] = (2 * incidence_df['Row']+5) % 1000\n","\n","incidence_df = incidence_df.sort_values(by=['h1','h2'])\n","\n","print(incidence_df)"]},{"cell_type":"code","execution_count":null,"id":"4d207e50-ab26-452d-827b-a3e6625e50e9","metadata":{"id":"4d207e50-ab26-452d-827b-a3e6625e50e9","outputId":"95ef84c7-7313-4e32-91cd-7db8dc24b9d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[inf inf inf]\n"," [inf inf inf]]\n","[[8. 1. 0.]\n"," [5. 1. 3.]]\n","\n","signature_matrix :\n","\n","    Document 1  Document 2  Document 3\n","h1         8.0         1.0         0.0\n","h2         5.0         1.0         3.0\n"]}],"source":["num_hashes = 2\n","num_docs = 3\n","signature_matrix = np.full((num_hashes, num_docs), np.inf)  # (2 x 3) matrix\n","print(signature_matrix)\n","\n","for i in range(len(unique_shingles)):\n","    if incidence_df.iloc[i, 1] == 1:  # Document 1\n","        signature_matrix[0, 0] = min(signature_matrix[0, 0], incidence_df.iloc[i]['h1'])\n","        signature_matrix[1, 0] = min(signature_matrix[1, 0], incidence_df.iloc[i]['h2'])\n","    if incidence_df.iloc[i, 2] == 1:  # Document 2\n","        signature_matrix[0, 1] = min(signature_matrix[0, 1], incidence_df.iloc[i]['h1'])\n","        signature_matrix[1, 1] = min(signature_matrix[1, 1], incidence_df.iloc[i]['h2'])\n","    if incidence_df.iloc[i, 3] == 1:  # Document 3\n","        signature_matrix[0, 2] = min(signature_matrix[0, 2], incidence_df.iloc[i]['h1'])\n","        signature_matrix[1, 2] = min(signature_matrix[1, 2], incidence_df.iloc[i]['h2'])\n","print(signature_matrix)\n","\n","signature_df = pd.DataFrame(signature_matrix, index=['h1', 'h2'], columns=[\"Document 1\", \"Document 2\", \"Document 3\"])\n","print(\"\\nsignature_matrix :\\n\")\n","print(signature_df)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}